# Lecture 2 - Deep Generative Models
![image](https://github.com/user-attachments/assets/01ac0aac-e68b-4233-bb0c-28ee6d8e201c)

How to represent a probability distribution p(x)?

![image](https://github.com/user-attachments/assets/67d14895-2c04-4b0c-bd71-0c54e145676f)

m number of things can happen but they HAVE to sum up to 1.

![image](https://github.com/user-attachments/assets/82332996-5c82-493b-b744-9ef880e16e24)

256*256*256-1

![image](https://github.com/user-attachments/assets/8f00e378-2c44-4acf-85d6-24bba0db1801)

Have to deal with the complexity. Represent the distribution. 
- Assume something that the random variables are related together

![image](https://github.com/user-attachments/assets/19e58bbf-2cba-45c9-afa6-dcb192f1cda6)

![image](https://github.com/user-attachments/assets/92c40387-a0f0-471c-baae-7ae0560f497f)

![image](https://github.com/user-attachments/assets/6fa44703-8bbd-4633-a6e0-883db6f103da)

![image](https://github.com/user-attachments/assets/9a0cac62-30cf-4754-8674-d0ea7262722a)

![image](https://github.com/user-attachments/assets/99173e45-fcde-41f4-a922-1b7de65e7c29)

![image](https://github.com/user-attachments/assets/dc642dcb-ee42-4174-b332-9c57c10a674d)

![image](https://github.com/user-attachments/assets/2dd8cffe-281b-42ee-ac37-6d1284e7f819)

- Bayesian are a way to simplify complicated distributions based on conditional indepedence assumptions

![image](https://github.com/user-attachments/assets/a092fc78-9ecb-426b-9e42-54d513870dfd)

![image](https://github.com/user-attachments/assets/4d9e3672-f5ac-4b46-981f-5e21062fec65)

![image](https://github.com/user-attachments/assets/4936260e-42d8-47f8-8daa-5b1f5302f8f7)

![image](https://github.com/user-attachments/assets/371150eb-d522-482e-8d6f-eb2c40b36e4c)

![image](https://github.com/user-attachments/assets/f700c935-afd2-47d5-9727-4d476f10a0ee)

